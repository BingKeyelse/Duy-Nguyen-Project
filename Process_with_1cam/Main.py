from import_all import*

class MainWindow(QMainWindow):
    def __init__(self):
        super().__init__()
        
        
        self.ui = Ui_MainWindow()
        self.ui.setupUi(self)

        # L·∫•y ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi c·ªßa file ƒëang ch·∫°y 
        self.current_file_path = os.path.dirname(os.path.abspath(__file__))

        # T·∫°o ra ƒë∆∞·ªùng d·∫´n v√† th∆∞ m·ª•c hi·ªán th·ªùi ƒë·ªÉ l∆∞u cho NG
        self.auto_check_and_create_folder_and_file_NG()
        
        # T·∫°o data SQLite
        self.database=['data_cam1.db','data_4cam.db']
        self.create_or_check_database()

        # c·∫≠p nh·∫≠p time v√† date sau 1s
        self.timer_date = QTimer(self)
        self.timer_date.timeout.connect(self.monitor_month_change)
        self.timer_date.start(60000)  # Update after 60s

        # Kh·ªüi ƒë·ªông setup li√™n quan ƒë·∫øt giao di·ªán ban ƒë·∫ßu
        self.initial_UI_setup()
        # L·∫•y gi√° tr·ªã cho vi·ªác s·ª≠ d·ª•ng cho calib ·∫£nh
        json_path = os.path.join(self.current_file_path, "data_calib", "calib_camera.json")

        self.frame_calibrate = FrameCalibrate(json_path)
        
        # Li√™n k·∫øt widget khi thay ƒë·ªïi v·ªõi label ƒë·ªÉ th·ªÉ hi·ªán ·∫£nh kh√¥ng b·ªã sai l·ªách
        self.ui.stackedWidget.currentChanged.connect(self.on_page_changed)

        ##### Cam 1
        # Kh·ªüi t·∫°o queue v·ªõi camera 1
        self.current_queue_cam1 = queue.Queue(maxsize=1)
        self.mode_pic_cam1= Value("i",0)  # 0: Cam 1, 1: Calib, 2: Sample
        self.image_sample_cam1=cv2.imread(os.path.join(self.current_file_path, "picture", "saved_sample.png"))

        


        # Khai b√°o bi·∫øn
        # H high, S high, V high, H low, S low, V low, bright, contrast, ratio, R cirrcle
        self.value_saved_cam1=[None, None, None, None, None, None, None, None, None, None] 
        self.value_now_cam1=[None, None, None, None, None, None, None, None, None, None] 
        self.image_cam1=None
        self.image_process=None

        

        Cam_1.start(self)
        Cam_1.slider_change_value_cam1(self)

        self.slider_timer = QTimer()
        self.slider_timer.setSingleShot(True)
        self.slider_timer.timeout.connect(lambda: self.process_cam_1(self.value_now_cam1))

        self.ui.but_saving_cam1.clicked.connect(lambda: Cam_1.save_data(self))
        self.ui.but_undo_cam1.clicked.connect(lambda: Cam_1.undo_data(self))
        self.ui.but_take_picture_cam1.clicked.connect(self.trigger_cam_1)
        self.ui.but_result_cam1.clicked.connect(lambda: Cam_1.switch_page(self))
        self.center_cam1=0

        # Kh·ªüi t·∫°o queue cho cam 2 3 4
        # AI
        self.queue_AI_cam2= Queue(maxsize=1)
        self.queue_AI_cam3= Queue(maxsize=1)
        self.queue_AI_cam4= Queue(maxsize=1)
        # GUI
        self.queue_GUI_cam2= Queue(maxsize=1)
        self.queue_GUI_cam3= Queue(maxsize=1)
        self.queue_GUI_cam4= Queue(maxsize=1)



        # ‚úÖ Kh·ªüi t·∫°o camera Basler
        self.camera = camera_Basler_multi(self.current_queue_cam1, self.queue_GUI_cam2, self.queue_GUI_cam3, self.queue_GUI_cam4) # Ch·ªâ c√≥ calib l√† g·ª≠i s·ªë 0 ƒëi
        self.camera.begin()

        process_AI = Process(target = run_AI, args=(self.queue_AI_cam2, self.queue_AI_cam3, self.queue_AI_cam4,))
        process_AI.start()

        #### Calib
        # Ch·ª©c nƒÉng c·ªßa Calib
        Calib.start(self) # kh·ªüi ƒë·ªông ban ƒë·∫ßu m√† kh√¥ng c·∫ßn ph·∫£i init
        self.ui.but_clear_calib.clicked.connect(lambda: Calib.clear_file_image(self))
        self.ui.but_take_calib.clicked.connect(self.trigger_cam_calib)
        self.ui.but_calib_calib.clicked.connect(self.auto_calib)
        
        ### Sample
        self.sample=Sample(self)
        self.ui.but_take_sample.clicked.connect(self.trigger_cam_sample)

        # Listwidget
        self.real_path_ng_cam1 = os.path.join(self.path_folder_today_ng_now_cam1, "real")
        self.virtual_path_ng_cam1 = os.path.join(self.path_folder_today_ng_now_cam1, "virtual")
        self.list_widget_ng=ListWidget(self)
        self.ui.but_NG_1_expand.clicked.connect(self.list_widget_ng.list_NG_cam1)
        self.ui.but_NG_1_icon.clicked.connect(self.list_widget_ng.list_NG_cam1)


        #### H√†m setup ch·ª©c nƒÉng cho UI nh∆∞ n√∫t nh·∫•n, chuy·ªÉn giao di·ªán
        UI_of_main_gui.update_ram_and_disk_time_and_date(self)
        UI_of_main_gui.change_window(self)
        UI_of_main_gui.tranfer_window(self)


        # C√°c h√†m threading
        thread1= threading.Thread(target=self.process_queue_cam1, daemon=True)
        thread1.start()

        #

    def check(self):
        print(f'OKOKOKOKOK: {self.value_now_cam1}')

    def read_file(self, link):
        data_read= open(link,"r")
        data=data_read.readlines()
        data_read.close()
        return data
    
    def exchange_data(self,data):
        processed = []
        for i, value in enumerate(data):
            try:
                if i == 7 :  # Ph·∫ßn t·ª≠ th·ª© 5 v√† 6 (index 4 v√† 5) -> float
                    processed.append(float(value))
                else:  # C√°c ph·∫ßn t·ª≠ kh√°c -> int
                    processed.append(int(value))
            except ValueError:
                processed.append(value)  # N·∫øu kh√¥ng chuy·ªÉn ƒë∆∞·ª£c, gi·ªØ nguy√™n
        return processed


    def on_page_changed(self, index):
        """C·∫≠p nh·∫≠t ·∫£nh khi trang c√≥ QLabel xu·∫•t hi·ªán"""
        if self.ui.stackedWidget.currentWidget() == self.ui.window_1:
            self.mode_pic_cam1.value=0
        elif self.ui.stackedWidget.currentWidget() == self.ui.window_2:
            QTimer.singleShot(50, lambda: Calib.check_file_in_folder(self))
            self.mode_pic_cam1.value=1
        elif self.ui.stackedWidget.currentWidget() == self.ui.window_3:
            self.mode_pic_cam1.value=2
        
    def initial_UI_setup(self):
        ## ƒê√≥ng m√†n h√¨nh full icon
        self.ui.window_expand.hide()

        # Setup m√†n Cam 1
        self.ui.show_pic_cam_cam1.setFixedSize(419, 428)
        self.ui.show_pic_thread_cam1.setFixedSize(419, 428)
        self.ui.show_pic_real_cam1.setFixedSize(419, 428)
        self.ui.show_pic_virtual_cam1.setFixedSize(419, 428)

        # Setup m√†n hinh listwidget cam 1 ng
        self.ui.show_pic_real_ng1cam.setFixedSize(300, 300)
        self.ui.show_pic_result_ng1cam.setFixedSize(300, 300)



        # T·∫°o QLabel m·ªõi tr√™n n·ªÅn c·ªßa m√†n h√¨nh hi·ªán ·∫£nh c·ªßa calib
        self.current_label = QLabel("          ", self.ui.show_pic_calib_calib)
        self.current_label.setStyleSheet("color: black; font-size: 16px;")

        self.ui.show_pic_calib_calib.setFixedSize(495, 492)

        # Setup m√†n Sample
        self.ui.show_pic_real_sample.setFixedSize(426, 508)
        self.ui.show_pic_sample_sample.setFixedSize(426, 508)

    def trigger_cam_1(self):
        self.mode_pic_cam1.value=0
        self.camera.trigger_cam()

     

    def trigger_cam_sample(self):
        self.mode_pic_cam1.value=2
        self.camera.trigger_cam()


    def trigger_cam_calib(self):
        if self.file_count_calib <7: # Khi kh·ªüi t·∫°o calib th√¨ bi·∫øt n√†y 
            #m√¨nh t·ª± ƒë·ªông l·∫•y ƒë∆∞·ª£c, th√¥ng qua h√†m start
            self.mode_pic_cam1.value=1 # 

            """G·ªçi trigger ƒë·ªÉ ch·ª•p ·∫£nh"""
            self.camera.trigger_cam()
        # Calib.check_file_in_folder(self)
        

    def process_queue_cam1(self):
        while True:
            if not self.current_queue_cam1.empty():
                image= self.current_queue_cam1.get()
                if self.mode_pic_cam1.value==1 and self.file_count_calib <7:
                    image_path = os.path.join(self.current_file_path, "data_calib", f"{self.file_count_calib+1}.png")
                    image=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
                    cv2.imwrite(image_path,image)
                    Calib.check_file_in_folder(self)

                elif self.mode_pic_cam1.value==2:
                    # Qua l·ªõp calib
                    image = self.frame_calibrate.undistortImage(image.copy()) 
                    image=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)


                    link = os.path.join(self.current_file_path, "picture", "sample_cam1.png")
                    cv2.imwrite(link,image)

                    self.sample.reset()

                else:
                    # Qua l·ªõp calib
                    image = self.frame_calibrate.undistortImage(image.copy())
                    image=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

                    # link = os.path.join(self.current_file_path, "picture", "test_cam1.png")
                    # cv2.imwrite(link,image)

                    self.image_cam1=image.copy()

                    self.image_sample_cam1=cv2.imread(os.path.join(self.current_file_path, "picture", "saved_sample.png"))

                    # Temp-matching h√¨nh ·∫£nh nguy√™n b·∫£n ƒë∆∞·ª£c v·∫Ω l√™n v√† h√¨nh ·∫£nh nh·ªè c·ªßa v√πng ƒë∆∞·ª£c scale
                    self.image_process, self.image_matching_process=self.template_matching(self.image_cam1.copy(),self.image_sample_cam1.copy())
                    if self.image_process is not None and self.image_matching_process is not None:

                        UI_of_main_gui.show_image_3chanel(self,self.image_process,self.ui.show_pic_cam_cam1)
                        self.process_cam_1(self.value_saved_cam1)
                    else: 
                        UI_of_main_gui.show_image_3chanel(self,self.image_cam1,self.ui.show_pic_cam_cam1)
                        self.ui.show_pic_real_cam1.clear()
                        self.ui.show_pic_thread_cam1.clear()
                    Cam_1.undo_data(self)

                    
                    

    def process_cam_1(self, value):
        if self.image_process is not None and self.image_matching_process is not None:
            self.time_start=time.time()
            # H√¨nh ·∫£nh c·∫Øt ra c·ªßa h√¨nh ch·ªØ nh·∫≠t ƒë√≥
            image_matching_process_drawed=self.image_matching_process.copy()
            picture_drawed=0

            contours=0

            image_process=cv2.convertScaleAbs(self.image_matching_process.copy(), alpha = value[7], beta = value[6])
            hsv = cv2.cvtColor(image_process.copy(), cv2.COLOR_BGR2HSV)

            # # T·∫°o mask b·∫±ng c√°ch ph√¢n ng∆∞·ª°ng
            upper_hsv= value[0],value[1], value[2]
            lower_hsv= value[3],value[4], value[5]
        
            mask = cv2.inRange(hsv, (lower_hsv), (upper_hsv))
            mask = cv2.bitwise_not(mask)

            # T√¨m contours
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            if contours:
                # T√¨m contour l·ªõn nh·∫•t
                largest_contour = max(contours, key=cv2.contourArea)

                # V·∫Ω bounding box th·∫≥ng
                x, y, w, h = cv2.boundingRect(largest_contour)
                padding = 15
                y1, y2 = max(0, y - padding), min(mask.shape[0], y + h + padding)
                x1, x2 = max(0, x - padding), min(mask.shape[1], x + w + padding)
                # cropped_image = mask[y:y+h, x:x+w]
                # C·∫Øt ·∫£nh v·ªõi v√πng m·ªü r·ªông
                cropped_image = mask[y1:y2, x1:x2]
                # cv2.imwrite(r"picture\test_circle.png", cropped_image)
                picture_drawed=image_matching_process_drawed[y1:y2, x1:x2]

                image_insert= self.check_bavia(picture_drawed, cropped_image, value)
                # print(cropped_image.shape)

                image_matching_process_drawed[y1:y2, x1:x2]=image_insert

                cv2.rectangle(image_matching_process_drawed, (x, y), (x + w, y + h), (0, 0, 255), 2)

            
                # UI_of_main_gui.show_image_3chanel(self,self.image_process,self.ui.show_pic_cam_cam1)
            
            UI_of_main_gui.show_image_3chanel(self,image_matching_process_drawed,self.ui.show_pic_real_cam1)
            UI_of_main_gui.show_image_3chanel(self,mask,self.ui.show_pic_thread_cam1)

    def check_bavia(self,image , image_gray, value):
        # T√¨m contour l·ªõn nh·∫•t (h√¨nh tr√≤n)
        contours, _ = cv2.findContours(image_gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if not contours:
            print("Kh√¥ng t√¨m th·∫•y h√¨nh tr√≤n trong ·∫£nh.")
            return None
    
        largest_contour = max(contours, key=cv2.contourArea)

        # X√°c ƒë·ªãnh t√¢m b·∫±ng bounding box c·ªßa contour
        x, y, w, h = cv2.boundingRect(largest_contour)
        cx, cy = int(x + w / 2), int(y + h / 2)  # T√¢m c·ªßa bounding box

        # T·∫°o mask t·ª´ contour
        mask = np.zeros_like(image_gray.copy())
        cv2.drawContours(mask, [largest_contour], -1, 255, thickness=1)

        # T·∫°o ·∫£nh m√†u ƒë·ªÉ v·∫Ω k·∫øt qu·∫£
        output_virtual = cv2.cvtColor(mask.copy(), cv2.COLOR_GRAY2BGR)

        # üîπ **B∆Ø·ªöC 1: T·∫°o b·∫£ng g√≥c tr∆∞·ªõc**
        angles_ref = np.linspace(0, 360, 360, endpoint=False)  # 360 gi√° tr·ªã t·ª´ 0¬∞ ƒë·∫øn 359¬∞

        # üîπ **B∆Ø·ªöC 2: T√≠nh to√°n nhanh g√≥c & kho·∫£ng c√°ch**
        contour_points = largest_contour[:, 0, :]  # L·∫•y danh s√°ch c√°c ƒëi·ªÉm bi√™n

        # T√≠nh kho·∫£ng c√°ch t·ª´ t√¢m ƒë·∫øn t·ª´ng ƒëi·ªÉm bi√™n
        dx = contour_points[:, 0] - cx
        dy = contour_points[:, 1] - cy
        distances = np.sqrt(dx**2 + dy**2)

        # T√≠nh g√≥c c·ªßa t·ª´ng ƒëi·ªÉm so v·ªõi t√¢m
        angles = np.arctan2(dy, dx) * 180 / np.pi  # Chuy·ªÉn ƒë·ªïi sang ƒë·ªô
        angles = np.mod(angles, 360)  # ƒê·∫£m b·∫£o g√≥c trong kho·∫£ng 0-360

        # üîπ **B∆Ø·ªöC 3: √Ånh x·∫° kho·∫£ng c√°ch v√†o m·∫£ng `r_list`**
        r_list = np.full(360, np.nan)

        # T√¨m g√≥c g·∫ßn nh·∫•t trong `angles_ref` b·∫±ng broadcasting
        angle_indices = np.abs(angles[:, None] - angles_ref).argmin(axis=1)

        # G√°n kho·∫£ng c√°ch v√†o r_list
        for i in range(len(angle_indices)):
            r_list[angle_indices[i]] = distances[i]

        # **N·ªôi suy gi√° tr·ªã NaN ƒë·ªÉ l√†m m∆∞·ª£t**
        valid_r = r_list[~np.isnan(r_list)]  # L·ªçc b·ªè gi√° tr·ªã NaN

        # Ki·ªÉm tra n·∫øu valid_r r·ªóng
        if valid_r.size == 0:
            print("‚ö†Ô∏è Kh√¥ng c√≥ gi√° tr·ªã h·ª£p l·ªá trong r_list! ƒê·∫∑t m·∫∑c ƒë·ªãnh r = 0")
            valid_r = np.array([0])  # Tr√°nh l·ªói khi t√≠nh mean

        for i in range(len(r_list)):
            if np.isnan(r_list[i]):
                start_idx = max(0, i - 5)
                end_idx = min(len(valid_r), i + 5)

                # N·∫øu ƒëo·∫°n c·∫ßn l·∫•y trung b√¨nh v·∫´n r·ªóng, th√¨ thay th·∫ø b·∫±ng gi√° tr·ªã m·∫∑c ƒë·ªãnh
                if valid_r[start_idx:end_idx].size == 0:
                    r_list[i] = 0  # Gi√° tr·ªã m·∫∑c ƒë·ªãnh khi kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá
                else:
                    r_list[i] = np.mean(valid_r[start_idx:end_idx])  # Trung b√¨nh c·ª•c b·ªô

        # **T√≠nh b√°n k√≠nh trung b√¨nh t·ª´ 100 gi√° tr·ªã nh·ªè nh·∫•t**
        first_120 = np.random.choice(valid_r[:80], min(25, len(valid_r[:80])), replace=False)  # L·∫•y ng·∫´u nhi√™n 50 gi√° tr·ªã t·ª´ gi·ªØa
        middle_50 = np.random.choice(valid_r[80:300], min(120, len(valid_r[80:300])), replace=False)  # L·∫•y ng·∫´u nhi√™n 50 gi√° tr·ªã t·ª´ gi·ªØa
        last_10 = np.random.choice(valid_r[300:], min(10, len(valid_r[300:])), replace=False)  # L·∫•y ng·∫´u nhi√™n 50 gi√° tr·ªã t·ª´ gi·ªØa

        # G·ªôp t·∫•t c·∫£ v√†o m·ªôt danh s√°ch
        selected_values = np.concatenate([ middle_50,last_10])

        # T√≠nh r_mean
        r_mean = np.median(np.sort(selected_values))

        # Debug s·ªë l∆∞·ª£ng g√≥c c√≥ gi√° tr·ªã h·ª£p l·ªá
        # print(f"S·ªë g√≥c c√≥ gi√° tr·ªã h·ª£p l·ªá: {np.count_nonzero(~np.isnan(r_list))} / 360")

        # N·ªôi suy n·∫øu c√≤n thi·∫øu
        valid_indices = np.where(~np.isnan(r_list))[0]
        valid_r_values = r_list[valid_indices]
        full_indices = np.arange(360)
        r_list = np.interp(full_indices, valid_indices, valid_r_values)

        # **V·∫Ω c√°c ƒë∆∞·ªùng tia**
        count_red = 0
        for angle in range(0, 360, 2):  # Gi·∫£m m·∫≠t ƒë·ªô tia (m·ªói 2 ƒë·ªô)
            theta = np.deg2rad(angle)
            r = r_list[angle]

            # X√°c ƒë·ªãnh m√†u s·∫Øc
            if value[9]< abs(r - r_mean):
                color = (0, 0, 255)  # ƒê·ªè n·∫øu b·∫•t th∆∞·ªùng
                count_red += 1  
            else:
                color = (0, 255, 0)  # Xanh n·∫øu ·ªïn

            # X√°c ƒë·ªãnh ƒëi·ªÉm k·∫øt th√∫c
            x_end, y_end = int(cx + r * np.cos(theta)), int(cy + r * np.sin(theta))

            # V·∫Ω ƒë∆∞·ªùng tia
            cv2.line(output_virtual, (cx, cy), (x_end, y_end), color, 1)
            if color==(0, 0, 255):
                cv2.line(image, (cx, cy), (x_end, y_end), color, 1)

        self.ui.show_value_now_cam1.setText(f'ƒêi·ªÉm NG ph√°t hi·ªán: {count_red}')

        if count_red > value[8]: #NG
            
            self.ui.label_ok_cam1.setStyleSheet(f"background: #c6c6c6;")
            self.ui.label_ng_cam1.setStyleSheet(f"background: #ff0772;")
            self.save_data_into_database_cam1(image.copy(), output_virtual.copy())
        else: # OK
            self.ui.label_ok_cam1.setStyleSheet(f"background: #47ff4d;")
            self.ui.label_ng_cam1.setStyleSheet(f"background: #c6c6c6;")
        UI_of_main_gui.show_image_3chanel(self,output_virtual,self.ui.show_pic_virtual_cam1)


        return image

    def save_data_into_database_cam1(self,image_real, image_thread):
        print(' ƒê∆∞a l∆∞u l·∫°i NG v√† ƒë∆∞a v√†o database')

        if not os.path.exists(self.real_path_ng_cam1):
            os.makedirs(self.real_path_ng_cam1)

        if not os.path.exists(self.virtual_path_ng_cam1):
            os.makedirs(self.virtual_path_ng_cam1)

        # L·∫•y t√™n cho ·∫£nh n√†o
        name_real   , link_real     = UI_of_main_gui.give_name_file(self,self.real_path_ng_cam1 )
        name_virtual, link_vitrual  = UI_of_main_gui.give_name_file(self,self.virtual_path_ng_cam1)

        cv2.imwrite(link_real, image_real)
        cv2.imwrite(link_vitrual, image_thread)
        
        self.save_to_database(self.database[0], name_real)
        self.time_end=time.time()

        print(f'FPS: {((self.time_end-self.time_start)):.5f}')


    def template_matching(self, image, sample):
        image_draw=None
        matched_region=None

        gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        gray_template = cv2.cvtColor(sample, cv2.COLOR_BGR2GRAY)

        # T·∫°o mask ƒë·ªÉ lo·∫°i b·ªè n·ªÅn ƒëen
        _, mask = cv2.threshold(gray_template, 10, 255, cv2.THRESH_BINARY)

        # Matching s·ª≠ d·ª•ng template matching
        result = cv2.matchTemplate(gray_img, gray_template, cv2.TM_CCOEFF_NORMED, mask=mask)

        # T√¨m v·ªã tr√≠ matching t·ªët nh·∫•t
        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)
        # Ki·ªÉm tra n·∫øu matching tr√™n 80%
        threshold = 0.75  # Ng∆∞·ª°ng t·ªëi thi·ªÉu 80%
        print(f'Ng∆∞·ª°ng hi·ªán t·∫°i: {max_val}')
        if max_val >= threshold:
            # V·∫Ω h√¨nh ch·ªØ nh·∫≠t quanh v√πng matching
            h, w = gray_template.shape
            top_left = max_loc
            bottom_right = (top_left[0] + w, top_left[1] + h)
            image_draw=image.copy()
            cv2.rectangle(image_draw, top_left, bottom_right, (0, 255, 0), 2)

            # C·∫Øt ·∫£nh v√πng matching
            matched_region = image[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]
        
        # center_x = (top_left[0] + bottom_right[0]) // 2
        # center_y = (top_left[1] + bottom_right[1]) // 2
        # self.center_cam1=(center_x,center_y)

        return image_draw, matched_region

    def auto_calib(self):
        if self.file_count_calib>=5:
            json_path = os.path.join(self.current_file_path, "data_calib", "calib_camera.json")

            path_folder = os.path.join(self.current_file_path, "data_calib")
            bmp_files = os.path.join(path_folder, "*.png")  # L·∫•y t·∫•t c·∫£ file bmp

            self.frame_calibrate = FrameCalibrate(json_path)

            image,ret= self.frame_calibrate.calibrateCameraMatrix(
            bmp_files, 
            (23, 15), 
            5, True)
            if ret !=0:
                UI_of_main_gui.show_image_3chanel(self, image, self.ui.show_pic_calib_calib)
                self.current_label.setStyleSheet(f"background-color: green;")

            else:
                self.current_label.setText(f"Kh√¥ng calib ƒë∆∞·ª£c")
                self.current_label.setStyleSheet(f"background-color: red;")

    def save_to_database(self, db_name, filename):
        print('Chuy·ªÉn ƒë∆∞·ªùng d·∫´n v√†o database')
        db_path = os.path.join(self.current_file_path, "data_txt", db_name)

        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        try:
            cursor.execute("INSERT INTO images (filename) VALUES (?)", (filename,))
            conn.commit()
            # print(f"‚úÖ ƒê√£ l∆∞u {filename} v√†o {db_name}")
        except sqlite3.IntegrityError:
            print(f"‚ö†Ô∏è File {filename} ƒë√£ t·ªìn t·∫°i trong {db_name}")
        finally:
            conn.close()  # ƒê√≥ng k·∫øt n·ªëi sau khi ho√†n th√†nh

    def get_recent_filenames(self, db_name, limit=100):
        """L·∫•y 100 file m·ªõi nh·∫•t t·ª´ database c·ª• th·ªÉ, m·ªü k·∫øt n·ªëi m·ªõi ƒë·ªÉ tr√°nh l·ªói thread"""
        db_path = os.path.join(self.current_file_path, "data_txt", db_name)

        try:
            # M·ªü k·∫øt n·ªëi m·ªõi trong t·ª´ng thread
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()

            # Truy v·∫•n 100 file g·∫ßn nh·∫•t
            cursor.execute("SELECT filename FROM images ORDER BY id DESC LIMIT ?", (limit,))
            filenames = [row[0] for row in cursor.fetchall()]

        except sqlite3.Error as e:
            print(f"‚ùå L·ªói SQLite ({db_name}): {e}")
            filenames = []

        finally:
            conn.close()  # ƒê√≥ng k·∫øt n·ªëi sau khi ho√†n th√†nh

        return filenames
    
    def create_or_check_database(self):
        self.db_connections = {}  # L∆∞u k·∫øt n·ªëi ƒë·ªÉ d·ªÖ d√πng sau n√†y
        for db_name in self.database:

            db_path = os.path.join(self.current_file_path, "data_txt", db_name)
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()
            
            # T·∫°o b·∫£ng n·∫øu ch∆∞a t·ªìn t·∫°i
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS images (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    filename TEXT UNIQUE
                )
            ''')
            conn.commit()
        
            # L∆∞u k·∫øt n·ªëi
            self.db_connections[db_name] = conn
        # n·∫øu c√≥ r·ªìi th√¨ n√≥ s·∫Ω kh√¥ng x√≥a d·ªØ li·ªáu c√≤n t·ªìn t·∫°i
    
    def close_all_databases(self):
        """ƒê√≥ng t·∫•t c·∫£ k·∫øt n·ªëi database khi tho√°t ch∆∞∆°ng tr√¨nh"""
        for db_name, conn in self.db_connections.items():
            conn.close()
            print(f"üîå ƒê√£ ƒë√≥ng {db_name}")

        self.db_connections.clear()  # X√≥a danh s√°ch k·∫øt n·ªëi

    def auto_check_and_create_folder_and_file_NG(self):
        link=os.path.join(self.current_file_path, "data_NG")

        self.year_backup=[]
        self.month_backup=[]
        self.path_ng_save_today=None

        today=datetime.today()
        # L·∫•y th·ªùi ƒëi·ªÉm hi·ªán t·∫°i
        self.month_now=today.month
        self.year_now=today.year

        # Tao folder hien tai de su dung cho muc dich luu tru
        self.path_folder_year_now   = os.path.join(link,str(self.year_now))
        self.path_folder_today_ng_now_cam1   = os.path.join(self.path_folder_year_now ,str(self.month_now),'cam1')
        self.path_folder_today_ng_now_4cam   = os.path.join(self.path_folder_year_now ,str(self.month_now),'4cam')
        ## N·∫øu kh√¥ng c√≥ th√¨ ph·∫£i t·∫°o
        if not os.path.exists(self.path_folder_today_ng_now_cam1):
            os.makedirs(self.path_folder_today_ng_now_cam1)

        if not os.path.exists(self.path_folder_today_ng_now_4cam):
            os.makedirs(self.path_folder_today_ng_now_4cam)

        # check lai folder voi muc dich chi co the chua duoc nhieu nhat 6 thang

        # check nƒÉm
        for year in os.listdir(link):
            self.year_backup.append(year)
        self.year_backup=sorted(self.year_backup)
        check_year_now=os.path.join(link, self.year_backup[-1])

        # Check th√°ng trong nƒÉm nh·ªè nh·∫•t trong chu·ªói
        for month in os.listdir(check_year_now):
            self.month_backup.append(month)
        self.month_backup=sorted(self.month_backup)

        if int(self.month_backup[-1])>=6:
            if len(self.month_backup)>6:
                for month in self.month_backup[0:-6]:
                    path_month_clear=os.path.join(check_year_now,month)

                    if os.path.exists(path_month_clear):
                        shutil.rmtree(path_month_clear)
            
            for year in self.year_backup[:-1]:
                path_year_to_clear=os.path.join(link, year)

                if os.path.exists(path_year_to_clear):
                    shutil.rmtree(path_year_to_clear)
        else:
            # s·ªë th√°ng c√≤n c√≥ th·ªÉ ch·ª©a l·∫°i b√™n kia l√† 
            month_cap=6-int(self.month_backup[-1])
            if len(self.year_backup) >= 2:
                path_year_old=os.path.join(link, self.year_backup[-2])
                for month in os.listdir(path_year_old):
                    # month=month
                    if int(month)<=(12-month_cap):
                        path_month_old_clear=os.path.join(path_year_old,month)
                        if os.path.exists(path_month_old_clear):
                            shutil.rmtree(path_month_old_clear)

    
    def monitor_month_change(self):
        current_month = datetime.now().month

        if current_month != self.month_now:  # N·∫øu th√°ng thay ƒë·ªïi
            self.auto_check_and_create_folder_and_file_NG()

    def closeEvent(self, event):
        # ƒê√≥ng c√°c database
        self.close_all_databases()
        print("Ng·∫Øt k·∫øt n·ªëi camera tho√°t ch∆∞∆°ng tr√¨nh")
        self.camera.close()
        event.accept()

class camera_Basler_multi:
    def __init__(self, pic_queue, pic_queue2, pic_queue3, pic_queue4):
        """Kh·ªüi t·∫°o class camera"""
        self.pic_queue = pic_queue

        self.pic_queue2 = pic_queue2
        self.pic_queue3 = pic_queue3
        self.pic_queue4 = pic_queue4

        self.cam = None
        self.converter = None
        self.running = True  # Bi·∫øn ki·ªÉm so√°t v√≤ng l·∫∑p thread trigger
        self.trigger_thread = None 


    def begin(self):
        """M·ªü camera v√† b·∫Øt ƒë·∫ßu ch·ª•p"""
        try:
            # ‚úÖ Kh·ªüi t·∫°o camera
            tlFactory = pylon.TlFactory.GetInstance()
            devices = tlFactory.EnumerateDevices()

            if len(devices) == 0:
                raise RuntimeError("üö® Kh√¥ng t√¨m th·∫•y camera!")

            self.cam = pylon.InstantCamera(pylon.TlFactory.GetInstance().CreateFirstDevice())
            self.cam.Open()
            self.cam.StopGrabbing()
            self.cam.StartGrabbing(pylon.GrabStrategy_LatestImageOnly)

            # ‚úÖ C·∫•u h√¨nh trigger ph·∫ßn c·ª©ng
            self.cam.LineSelector.SetValue('Line1')  
            self.cam.LineMode.SetValue('Input')
            # print(f"üì° Trigger Mode: {self.cam.TriggerMode.GetValue()}")
            # self.cam.TriggerMode.SetValue("On")


            # ‚úÖ C·∫•u h√¨nh converter cho ·∫£nh
            self.converter = pylon.ImageFormatConverter()
            self.converter.OutputPixelFormat = pylon.PixelType_BGR8packed
            self.converter.OutputBitAlignment = pylon.OutputBitAlignment_MsbAligned

            print("‚úÖ Camera ƒë√£ s·∫µn s√†ng!")

            # ‚úÖ B·∫Øt ƒë·∫ßu theo d√µi t√≠n hi·ªáu trigger ph·∫ßn c·ª©ng
            self.trigger_thread = self.monitor_trigger()
            self.trigger_thread.start()

        except Exception as e:
            print(f"‚ùå L·ªói kh·ªüi t·∫°o camera: {e}")

    def reconnect_camera(self):
        """Th·ª≠ k·∫øt n·ªëi l·∫°i camera"""
        try:
            self.cam.Close()  # ƒê√≥ng camera n·∫øu n√≥ v·∫´n m·ªü
            time.sleep(0.5)  # ƒê·ª£i m·ªôt ch√∫t tr∆∞·ªõc khi m·ªü l·∫°i

            self.cam = pylon.InstantCamera(pylon.TlFactory.GetInstance().CreateFirstDevice())
            self.cam.Open()
            print("‚úÖ Camera ƒë√£ k·∫øt n·ªëi l·∫°i th√†nh c√¥ng!")
        
        except Exception as e:
            print(f"‚ö† Kh√¥ng th·ªÉ k·∫øt n·ªëi l·∫°i camera: {e}")
    
    def monitor_trigger(self):
        def run():
            """Lu·ªìng ch·∫°y li√™n t·ª•c ki·ªÉm tra t√≠n hi·ªáu t·ª´ Line1"""
            previous_status = 0  # Tr·∫°ng th√°i tr∆∞·ªõc ƒë√≥ c·ªßa Line1
            while self.running:
                try:
                    line_status = self.cam.LineStatus.GetValue()
                    if line_status == 1 and previous_status == 0:  # Ch·ªâ ch·ª•p khi c√≥ s·ª± thay ƒë·ªïi t·ª´ 0 ‚Üí 1
                        print("üéØ T√≠n hi·ªáu k√≠ch ho·∫°t! Ch·ª•p ·∫£nh...")
                        self.trigger_cam()

                    previous_status = line_status  # C·∫≠p nh·∫≠t tr·∫°ng th√°i
                    time.sleep(0.008)  # Tr√°nh ti√™u t·ªën CPU qu√° nhi·ªÅu
                except pylon.RuntimeException as e:
                    print(f"‚ùå L·ªói khi theo d√µi trigger: {e}")
                    print("üîÑ ƒêang th·ª≠ k·∫øt n·ªëi l·∫°i camera...")
                    self.reconnect_camera()
                    time.sleep(1)  # ƒê·ª£i m·ªôt ch√∫t r·ªìi th·ª≠ l·∫°i
                    
                except Exception as e:
                    print(f"‚ùå L·ªói kh√°c: {e}")
                    time.sleep(1)  # ƒê·ª£i 1 gi√¢y r·ªìi th·ª≠ l·∫°i
        return  threading.Thread(target=run, daemon=True)

    def trigger_cam(self):
        """Ch·ª•p ·∫£nh t·ª´ camera"""
        if self.cam is None or not self.cam.IsGrabbing():
            print("‚ö† Camera ch∆∞a s·∫µn s√†ng!")
            return

        try:
            grab_result = self.cam.RetrieveResult(5000, pylon.TimeoutHandling_ThrowException)
            if grab_result.GrabSucceeded():
                img = self.converter.Convert(grab_result).GetArray()
                image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

                # ‚úÖ Ki·ªÉm tra tr∆∞·ªõc khi ƒë∆∞a ·∫£nh v√†o queue
                if not self.pic_queue.full():
                    self.pic_queue.put(image)
                    print("üì∏ ·∫¢nh ƒë√£ ƒë∆∞·ª£c g·ª≠i v·ªÅ GUI!")

        except Exception as e:
            print(f"‚ùå L·ªói ch·ª•p ·∫£nh: {e}")

    def close(self):
        self.running=False
        if self.trigger_thread is not None:
            self.trigger_thread.join()
        """D·ª´ng camera"""
        if self.cam is not None:
            self.cam.StopGrabbing()
            self.cam.Close()
        
        print("‚úÖ Camera ƒë√£ ƒë∆∞·ª£c ƒë√≥ng an to√†n.")

#class_calib_images
class NumpyEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        return json.JSONEncoder.default(self, obj)
    
class FrameCalibrate:

    CAMERA_MATRIX = 'Camera matrix'
    OPPT_CAMERA_MATRIX = 'Optimal camera matrix'
    DISTORT_ROI = 'Distortion ROI'
    DISTORTION = 'Distortion'
    FRAME_SIZE = 'Frame size'

    # Camera calibration matrix
    camera_matrix = []
    optimal_camera_matrix = []
    distort_roi = []
    camera_dist = []
    homo_matrix = []
    frame_size = (0, 0)

    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)

    def __init__(self, config_path):
        self.cfg_file_path = str(config_path)
        self.camera_matrix = self.loadMatrix(self.CAMERA_MATRIX)
        self.camera_dist = self.loadMatrix(self.DISTORTION)
        self.frame_size = self.loadMatrix(self.FRAME_SIZE)
        self.optimal_camera_matrix = self.loadMatrix(self.OPPT_CAMERA_MATRIX)
        self.distort_roi = self.loadMatrix(self.DISTORT_ROI)

    def loadMatrix(self, key):
        obj_text = codecs.open(self.cfg_file_path, 'r', encoding='utf-8').read()
        json_load  = json.loads(obj_text)
        value = json_load.get(key)
        if value is not None:
            matrix_restored = np.asarray(json_load[key])
        else:
            matrix_restored = []
        return matrix_restored

    def saveMatrix(self, key, value):
        print(key)
        print(value)
        obj_text = codecs.open(self.cfg_file_path, 'r', encoding='utf-8').read()
        json_load  = json.loads(obj_text)
        json_load[key] = np.asarray(value)
        json.dump(json_load, 
                    (codecs.open(self.cfg_file_path, 'w', encoding='utf-8')), 
                    indent=4, 
                    cls=NumpyEncoder)

    def calibrateCameraMatrix(self, input_images_path, grid_size, distance, use_chess_board = True):

        grid_points = np.zeros((grid_size[0] * grid_size[1], 3), np.float32)
        grid_points[:,:2] = np.mgrid[0:grid_size[0],0:grid_size[1]].T.reshape(-1,2)
        grid_points = grid_points * distance

        object_points = []
        image_points = []
        input_images = glob.glob(input_images_path)

        for counter in range(len(input_images)):
            # image = mpimg.imread(input_images[counter], )
            image = cv2.imread(input_images[counter], cv2.IMREAD_GRAYSCALE)

            
            if (len(image.shape) == 2) :
                gray_image = image
            else :
                gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

            if counter == 0:
                self.frame_size = gray_image.shape[::-1]
                # print(self.frame_size)
                # print(gray_image.shape[::-1])

            if use_chess_board:
                ret, corners = cv2.findChessboardCorners(image, grid_size, None)
            else:
                ret, corners = cv2.findCirclesGrid(image, grid_size, None)

            if ret == True:

                object_points.append(grid_points)
                corners2 = cv2.cornerSubPix(image, corners, (11,11), (-1,-1), self.criteria)
                image_points.append(corners)

                # color_image = cv.cvtColor(img, cv.COLOR_GRAY2BGR)
                image_copy = image.copy()
                color_image = cv2.cvtColor(image_copy, cv2.COLOR_GRAY2BGR)
                cv2.drawChessboardCorners(color_image, grid_size, corners2, ret)
                # save_path = result_images_path.replace('*', str(counter))
                # cv2.imwrite(save_path, image_copy)

            counter += 1
        try:
            ret, self.camera_matrix, self.camera_dist, rvecs, tvecs =  cv2.calibrateCamera(
                                                                        object_points, 
                                                                        image_points, 
                                                                        self.frame_size, 
                                                                        None, None)

            self.optimal_camera_matrix, self.distort_roi = cv2.getOptimalNewCameraMatrix(
                                                    self.camera_matrix,
                                                    self.camera_dist,
                                                    self.frame_size, 1, 
                                                    self.frame_size)

            self.saveMatrix(self.CAMERA_MATRIX, self.camera_matrix)
            self.saveMatrix(self.DISTORTION, self.camera_dist)
            self.saveMatrix(self.FRAME_SIZE, self.frame_size)
            self.saveMatrix(self.OPPT_CAMERA_MATRIX, self.optimal_camera_matrix)
            self.saveMatrix(self.DISTORT_ROI, self.distort_roi)
            return color_image,ret
        except Exception as e:
            print(f"‚ùå L·ªói calibration: {e}")
            return None,0
        
    def undistortImage(self, image):
        image_undistort = cv2.undistort(image, self.camera_matrix, 
                                        self.camera_dist, None, self.optimal_camera_matrix)

        x, y, w, h = self.distort_roi
        image_undistort = image_undistort[y:y+h, x:x+w]
        return image_undistort

def run_AI(cam2, cam3, cam4):
    while True:
        return 0

    

if __name__ == "__main__":
    multiprocessing.freeze_support()

    ### Convert 
    # auto_tranfer_file.convert_ui_qrc_to_py()
    app = QApplication(sys.argv)
    main_win = MainWindow()
    main_win.show()
    sys.exit(app.exec())
